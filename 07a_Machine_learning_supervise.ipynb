{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Le machine learning\n",
    "\n",
    "- Machine Learning : Techniques de calcul permettant aux ordinateurs d’apprendre à exécuter des tâches en s’inspirant de patterns perçus sur des données, avec peu d’intervention humaine. Les tâches se résument souvent à de la prédiction.\n",
    "\n",
    "![image](./images/ml1.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Quelques exemples\n",
    "\n",
    "- Prestation de service : identification des paramètres de prédisposition à la résiliation (churn)\n",
    "- Marketing: identification de segments distincts de consommateurs \n",
    "- Production : identification de paramètres induisant des défaillances\n",
    "- Pharmaceutique: classification de médicaments selon le profil chimique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le data mining vs le machine learning\n",
    "\n",
    "- Data Mining : recherche d’information et de patterns cachés dans une base de données isolée ou en croisant plusieurs bases. C’est l’être humain qui explore et prend des décisions.\n",
    "- Le data mining s’appuie sur des techniques et algorithmes issus de la statistique et de la gestion de bases de données.\n",
    "- Les données exploitées ont souvent une taille considérable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![image](./images/trend-ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les outils\n",
    "\n",
    "![image](./images/poll-ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Les types de machine learning\n",
    "\n",
    "- Les algorithmes de machine learning peuvent être rassemblés dans 3 groupes principaux :\n",
    "   - L'apprentissage supervisé\n",
    "     - Cible (variable dépendante qualitative ou quantitative)\n",
    "     - Prédicteurs (variables indépendantes)\n",
    "     - Régression, arbre de decision, foret aléatoire, kNN, regression logistique, SVM…\n",
    "\n",
    "   - L'apprentissage non supervisé\n",
    "     - Pas de variable dépendante, pas de modélisation\n",
    "     - Classer des individus dans différents groups ou trouver des associations\n",
    "     - Apriori algorithm, K-means.\n",
    "\n",
    "   - L'apprentissage par renforcement\n",
    "     - Apprentissage pour prendre des décisions spécifique afin d’aboutir à un but précis\n",
    "     - Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L’analyse de données et le machine learning avec Python\n",
    "\n",
    "Le package la plus adaptée pour faire du data mining et du machine learning est la package **scikit-learn**\n",
    "\n",
    "\n",
    "Ce package propose des fonctions prédéfinies pour un grand nombre de méthodes\n",
    "\n",
    "- La classification : SVM, plus proches voisins, random forest…\n",
    "- Les régressions : linéaire, ridge, Lasso…\n",
    "- Le clustering : k-means…\n",
    "- L’analyse de données :  ACP, DA…\n",
    "\n",
    "Dans le cadre de cette formation, l'objectf n'est pas de décrire la théorie des méthodes mais plutôt de comprendre l'utilisation de Python pour les appliquer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# L’apprentissage supervisé avec Scikit-Learn\n",
    "Les méthodes d’apprentissage supervisé sont les méthodes actuellement les plus\n",
    "utilisées en data science. Il s’agit d’essayer de prédire une variable cible et d’utiliser\n",
    "différentes méthodes pour arriver à cette fin.\n",
    "Nous allons illustrer ces méthodes de traitement de données avec du code et des\n",
    "cas pratiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Les données et leur transformation\n",
    "Ce jeu de données est composé de 3333 individus et de 18 variables. Il est stocké dans un fichier csv, nommé telecom.csv, accessible dans le répertoire Data. On le récupère en utilisant Pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "churn=pd.read_csv(\"./data/telecom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3333 entries, 0 to 3332\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   State           3333 non-null   object \n",
      " 1   Account Length  3333 non-null   int64  \n",
      " 2   Area Code       3333 non-null   int64  \n",
      " 3   Phone           3333 non-null   object \n",
      " 4   Int'l Plan      3333 non-null   object \n",
      " 5   VMail Plan      3333 non-null   object \n",
      " 6   VMail Message   3333 non-null   int64  \n",
      " 7   Day Mins        3333 non-null   float64\n",
      " 8   Day Calls       3333 non-null   int64  \n",
      " 9   Day Charge      3333 non-null   float64\n",
      " 10  Eve Mins        3333 non-null   float64\n",
      " 11  Eve Calls       3333 non-null   int64  \n",
      " 12  Eve Charge      3333 non-null   float64\n",
      " 13  Night Mins      3333 non-null   float64\n",
      " 14  Night Calls     3333 non-null   int64  \n",
      " 15  Night Charge    3333 non-null   float64\n",
      " 16  Intl Mins       3333 non-null   float64\n",
      " 17  Intl Calls      3333 non-null   int64  \n",
      " 18  Intl Charge     3333 non-null   float64\n",
      " 19  CustServ Calls  3333 non-null   int64  \n",
      " 20  Churn?          3333 non-null   object \n",
      "dtypes: float64(8), int64(8), object(5)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "churn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Les données\n",
    "\n",
    "Ce jeu de données n’a pas de données manquantes et nous allons devoir effectuer\n",
    "quelques transformations pour l’adapter à nos traitements. Nous voyons par exemple qu’il est composé de trois colonnes object.\n",
    "\n",
    "Nous pouvons afficher les statistiques descriptives pour les colonnes object :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>3333</td>\n",
       "      <td>51</td>\n",
       "      <td>WV</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <td>3333</td>\n",
       "      <td>3333</td>\n",
       "      <td>351-9037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Int'l Plan</th>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VMail Plan</th>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>2411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Churn?</th>\n",
       "      <td>3333</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count unique       top  freq\n",
       "State       3333     51        WV   106\n",
       "Phone       3333   3333  351-9037     1\n",
       "Int'l Plan  3333      2        no  3010\n",
       "VMail Plan  3333      2        no  2411\n",
       "Churn?      3333      2    False.  2850"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn.describe(include=\"object\").transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformation des données\n",
    "\n",
    "On voit que les données sont toutes binaires. \n",
    "\n",
    "Pour les variables binaires, il nous suffit de les recoder avec Scikit-Learn pour obtenir des données exploitables. Par\n",
    "ailleurs, il existe une autre variable qualitative dans notre jeu de données, Area Code,\n",
    "qui est numérique mais avec trois modalités :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "415    1655\n",
       "510     840\n",
       "408     838\n",
       "Name: Area Code, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[\"Area Code\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## La préparation des données\n",
    "\n",
    "Nous allons utiliser le processus de traitement classique pour transformer nos\n",
    "données avec Scikit-Learn. Dans ce cas, nous n’avons pas de données manquantes,\n",
    "nous travaillons donc sur la transformation des variables qualitatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on définit les colonnes\n",
    "# les colonnes quantitatives\n",
    "col_quanti = ['Day Mins', 'Day Calls', 'Day Charge',\n",
    "       'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls',\n",
    "       'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge',\n",
    "       'CustServ Calls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prédire l’attrition des clients\n",
    "Lorsqu’on veut prédire une variable binaire, on devra avoir une colonne du type\n",
    "binaire. On préfère généralement un codage 0/1 afin de garder un type entier simple à gérer. \n",
    "\n",
    "Les variables explicatives x auront été préparées de manière intelligente afin de bien appliquer nos modèles.\n",
    "\n",
    "On crée donc x et y :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = churn[col_quanti]\n",
    "y = churn[\"Churn?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Séparation des données\n",
    "\n",
    "Pour la séparation, on utilise la fonction train_test_split() de Scikit-Learn.\n",
    "\n",
    "Cette fonction permet de créer automatiquement autant de structures que nécessaire\n",
    "à partir de nos données. \n",
    "\n",
    "Elle utilise une randomisation des individus et ensuite une séparation en fonction d’un paramètre du type test_size :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# on importe la fonction\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dans certains cas, il peut arriver qu’il y ait une forte disparité de distribution des\n",
    "modalités entre les proportions d’acceptation et de refus. On peut vouloir faire en\n",
    "sorte que les répartitions des modalités de y soient égales dans les différents échantillons,\n",
    "on pourra alors utiliser une stratification. On va utiliser une stratification en\n",
    "prenant y comme base pour effectuer la stratification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bien séparé !\n"
     ]
    }
   ],
   "source": [
    "assert x_train.shape[0] == y_train.shape[0]\n",
    "print(\"Bien séparé !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ainsi les deux échantillons _train et _test ont la même distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Le choix et l’ajustement de l’algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout au long de ce Notebook, nous allons essayer d'ajouter un nouveau modèle, il s'agit du modèle GBM\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ensuite, on crée un objet à partir de la classe du modèle en lui fournissant les\n",
    "hyperparamètres dont il a besoin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "modele_rf = RandomForestClassifier(n_estimators=100)\n",
    "modele_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "modele_gbm = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dans ce cas, on prend les hyperparamètres par défaut.\n",
    "\n",
    "On peut ensuite ajuster notre modèle en utilisant les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "modele_rf.fit(x_train,y_train)\n",
    "modele_knn.fit(x_train,y_train)\n",
    "modele_gbm.fit(x_train,y_train)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une fois qu’on a estimé les paramètres du modèle, on va pouvoir extraire des\n",
    "informations. De nouveaux attributs de chaque classe apparaissent, ils se terminent par le symbole underscore _ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Day Mins</th>\n",
       "      <td>0.147884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day Calls</th>\n",
       "      <td>0.052154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day Charge</th>\n",
       "      <td>0.160983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve Mins</th>\n",
       "      <td>0.084640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve Calls</th>\n",
       "      <td>0.049853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eve Charge</th>\n",
       "      <td>0.081246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night Mins</th>\n",
       "      <td>0.054861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night Calls</th>\n",
       "      <td>0.052851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night Charge</th>\n",
       "      <td>0.055032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intl Mins</th>\n",
       "      <td>0.051735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intl Calls</th>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intl Charge</th>\n",
       "      <td>0.052566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustServ Calls</th>\n",
       "      <td>0.121896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "Day Mins        0.147884\n",
       "Day Calls       0.052154\n",
       "Day Charge      0.160983\n",
       "Eve Mins        0.084640\n",
       "Eve Calls       0.049853\n",
       "Eve Charge      0.081246\n",
       "Night Mins      0.054861\n",
       "Night Calls     0.052851\n",
       "Night Charge    0.055032\n",
       "Intl Mins       0.051735\n",
       "Intl Calls      0.034300\n",
       "Intl Charge     0.052566\n",
       "CustServ Calls  0.121896"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(modele_rf.feature_importances_,index=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ce qui va nous intéresse avant tout, c’est de prédire avec notre modèle. Pour cela nous allons utiliser la méthode .predict() :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_predict_rf = modele_rf.predict(x_test)\n",
    "y_predict_knn = modele_knn.predict(x_test)\n",
    "y_predict_gbm = modele_gbm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On obtient ainsi une valeur prédite pour les éléments de notre échantillon de\n",
    "validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Les indicateurs pour valider un modèle\n",
    "La partie validation d’un modèle d’apprentissage supervisé est extrêmement\n",
    "importante. L’objectif d’un modèle d’apprentissage supervisé est de prédire une\n",
    "valeur la plus proche possible de la réalité. Nous différencions trois types d’indices\n",
    "en fonction du type de variable cible. Tous les indicateurs de qualité du modèle sont\n",
    "stockés dans le module *metrics* de Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Le pourcentage de bien classés\n",
    "Il s’agit de l’indicateur le plus connu. On le nomme accuracy. Il est calculé à partir du rapport entre le nombre d’individus bien classés et le nombre total d’individus dans l’échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de bien classés pour le modèle RF : 0.905\n",
      "Pourcentage de bien classés pour le modèle kNN :0.873\n",
      "Pourcentage de bien classés pour le modèle GBM :0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "accuracy_modele_rf = accuracy_score(y_test,y_predict_rf)\n",
    "accuracy_modele_knn = accuracy_score(y_test,y_predict_knn)\n",
    "accuracy_modele_gbm = accuracy_score(y_test,y_predict_gbm)\n",
    "print(\"Pourcentage de bien classés pour le modèle RF : %.3f\" %(accuracy_modele_rf))\n",
    "print(\"Pourcentage de bien classés pour le modèle kNN :%.3f\" %(accuracy_modele_knn))\n",
    "print(\"Pourcentage de bien classés pour le modèle GBM :%.3f\" %(accuracy_modele_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## La matrice de confusion\n",
    "Il s’agit d’un autre indicateur important pour juger de la qualité d’un modèle, il n’est pas défini par une seule valeur mais par une matrice dans laquelle on peut lire le croisement entre les valeurs observées et les valeurs prédites à partir du modèle. \n",
    "\n",
    "Pour calculer cette matrice, on pourra utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion pour le modèle RF :\n",
      "[[923  17]\n",
      " [ 88  72]]\n",
      "Matrice de confusion pour le modèle kNN :\n",
      "[[923  17]\n",
      " [123  37]]\n",
      "Matrice de confusion pour le modèle GBM :\n",
      "[[921  19]\n",
      " [ 87  73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix_rf=confusion_matrix(y_test,y_predict_rf)\n",
    "confusion_matrix_knn=confusion_matrix(y_test,y_predict_knn)\n",
    "confusion_matrix_gbm=confusion_matrix(y_test,y_predict_gbm)\n",
    "print(\"Matrice de confusion pour le modèle RF :\",\n",
    "confusion_matrix_rf, sep=\"\\n\")\n",
    "print(\"Matrice de confusion pour le modèle kNN :\",\n",
    "confusion_matrix_knn, sep=\"\\n\")\n",
    "print(\"Matrice de confusion pour le modèle GBM :\",\n",
    "confusion_matrix_gbm, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## L’aire sous la courbe ROC\n",
    "La courbe ROC est un indicateur important mais on préfère souvent une valeur plutôt\n",
    "qu’une courbe afin de comparer nos modèles. Pour cela, on utilise l’aire sous la courbe\n",
    "ROC (AUC). Cette aire est calculée directement à partir de la courbe ROC. Ainsi, un\n",
    "modèle aléatoire aura une AUC de 0.5 et un modèle parfait aura une AUC de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aire sous la courbe ROC pour le modèle RF : 0.8797639627659575\n",
      "Aire sous la courbe ROC pour le modèle kNN : 0.6991190159574467\n",
      "Aire sous la courbe ROC pour le modèle GBM : 0.883530585106383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_modele_rf=roc_auc_score(y_test, modele_rf.predict_proba(x_test)[:,1])\n",
    "auc_modele_knn=roc_auc_score(y_test,modele_knn.predict_proba(x_test)[:,1])\n",
    "auc_modele_gbm=roc_auc_score(y_test,modele_gbm.predict_proba(x_test)[:,1])\n",
    "\n",
    "print(\"Aire sous la courbe ROC pour le modèle RF :\" ,auc_modele_rf)\n",
    "print(\"Aire sous la courbe ROC pour le modèle kNN :\" ,auc_modele_knn)\n",
    "print(\"Aire sous la courbe ROC pour le modèle GBM :\" ,auc_modele_gbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## La validation croisée\n",
    "Jusqu’ici nous avons utilisé des indicateurs basés sur une seule occurrence de test. Ceci veut dire qu’on ne teste notre modèle que sur un seul échantillon.\n",
    "\n",
    "Une approche alternative souvent utilisée est la validation croisée. Celle-ci est en fait basée sur la répétition de l’estimation et de la validation sur des données différentes.\n",
    "\n",
    "Pour obtenir ce cv-score, on utilise :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC pour RF : 0.850 (+/- 0.043)\n",
      "AUC pour kNN : 0.622 (+/- 0.107)\n",
      "AUC pour GBM : 0.844 (+/- 0.050)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_rf = cross_val_score(modele_rf, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "scores_knn = cross_val_score(modele_knn, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "scores_gbm = cross_val_score(modele_gbm, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"AUC pour RF : %.3f (+/- %.3f)\"% (scores_rf.mean(), scores_rf.std() * 2))\n",
    "print(\"AUC pour kNN : %.3f (+/- %.3f)\"% (scores_knn.mean(),scores_knn.std() * 2))\n",
    "print(\"AUC pour GBM : %.3f (+/- %.3f)\"% (scores_gbm.mean(),scores_gbm.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## L’ajustement des hyperparamètres d’un modèle\n",
    "\n",
    "L’une des tâches du data scientist est de trouver le meilleur modèle possible. La\n",
    "plupart des modèles de machine learning ont des hyperparamètres. Il s’agit de paramètres\n",
    "du modèle qui sont définis en amont de l’ajustement.\n",
    "\n",
    "Scikit-Learn propose une classe GridSearchCV permettant d’implémenter cette\n",
    "recherche d’hyperparamètres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On va donc devoir définir les hyperparamètres que l’on souhaite tester. Pour cela,\n",
    "on utilisera un dictionnaire d’hyperparamètres, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dico_param= {\"max_depth\":[3,5,7,10], \"n_estimators\":[10,20,50,100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On va encore utiliser l’accuracy pour valider notre modèle. Finalement, nous allons\n",
    "utiliser une validation croisée à cinq groupes pour valider les résultats.\n",
    "Le nouvel objet est le suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "recherche_hyper = GridSearchCV(RandomForestClassifier(), \n",
    "                               dico_param, \n",
    "                               scoring=\"accuracy\",cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Une fois qu’on a créé cet objet, on peut lui joindre les données afin d’estimer les\n",
    "meilleurs paramètres du modèle.\n",
    "\n",
    "Cette étape peut être très longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "recherche_hyper.fit(x_train, y_train)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(recherche_hyper.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9028169861859331\n"
     ]
    }
   ],
   "source": [
    "print(recherche_hyper.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019546</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 10}</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.863535</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.867713</td>\n",
       "      <td>0.864753</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035908</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 20}</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.869955</td>\n",
       "      <td>0.866097</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083763</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 50}</td>\n",
       "      <td>0.865772</td>\n",
       "      <td>0.870246</td>\n",
       "      <td>0.868009</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.872197</td>\n",
       "      <td>0.866097</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.167953</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 100}</td>\n",
       "      <td>0.868009</td>\n",
       "      <td>0.872483</td>\n",
       "      <td>0.868009</td>\n",
       "      <td>0.854260</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.867440</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 10}</td>\n",
       "      <td>0.874720</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.869955</td>\n",
       "      <td>0.899103</td>\n",
       "      <td>0.885803</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.041681</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 20}</td>\n",
       "      <td>0.883669</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.894855</td>\n",
       "      <td>0.869955</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.887140</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 50}</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>0.879195</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.874439</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.884906</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.200669</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.010174</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.901566</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.896549</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025133</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 10}</td>\n",
       "      <td>0.897092</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.894855</td>\n",
       "      <td>0.872197</td>\n",
       "      <td>0.917040</td>\n",
       "      <td>0.897445</td>\n",
       "      <td>0.014847</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048462</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 20}</td>\n",
       "      <td>0.897092</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.897092</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.896550</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.119090</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 50}</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.903803</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.887892</td>\n",
       "      <td>0.908072</td>\n",
       "      <td>0.898343</td>\n",
       "      <td>0.007313</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.238158</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.010170</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 100}</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.892617</td>\n",
       "      <td>0.885650</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.897445</td>\n",
       "      <td>0.007451</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.031920</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>0.894855</td>\n",
       "      <td>0.901566</td>\n",
       "      <td>0.885906</td>\n",
       "      <td>0.890135</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.896555</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.056658</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 20}</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.881432</td>\n",
       "      <td>0.908277</td>\n",
       "      <td>0.883408</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.165361</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 50}</td>\n",
       "      <td>0.903803</td>\n",
       "      <td>0.899329</td>\n",
       "      <td>0.903803</td>\n",
       "      <td>0.881166</td>\n",
       "      <td>0.919283</td>\n",
       "      <td>0.901477</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.314753</td>\n",
       "      <td>0.012398</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.906040</td>\n",
       "      <td>0.910515</td>\n",
       "      <td>0.901566</td>\n",
       "      <td>0.885650</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.902817</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.019546      0.000796         0.002205        0.000391   \n",
       "1        0.035908      0.001411         0.003193        0.000739   \n",
       "2        0.083763      0.002597         0.005397        0.000482   \n",
       "3        0.167953      0.005152         0.010363        0.001021   \n",
       "4        0.022142      0.000398         0.002393        0.000489   \n",
       "5        0.041681      0.000968         0.002792        0.000399   \n",
       "6        0.103937      0.003765         0.005771        0.000427   \n",
       "7        0.200669      0.003454         0.010174        0.000398   \n",
       "8        0.025133      0.000400         0.002393        0.000489   \n",
       "9        0.048462      0.001221         0.003192        0.000399   \n",
       "10       0.119090      0.002345         0.005984        0.000004   \n",
       "11       0.238158      0.005376         0.010170        0.000402   \n",
       "12       0.031920      0.001077         0.002589        0.000792   \n",
       "13       0.056658      0.002224         0.003380        0.000476   \n",
       "14       0.165361      0.015316         0.006773        0.000756   \n",
       "15       0.314753      0.012398         0.012774        0.001165   \n",
       "\n",
       "   param_max_depth param_n_estimators                                  params  \\\n",
       "0                3                 10    {'max_depth': 3, 'n_estimators': 10}   \n",
       "1                3                 20    {'max_depth': 3, 'n_estimators': 20}   \n",
       "2                3                 50    {'max_depth': 3, 'n_estimators': 50}   \n",
       "3                3                100   {'max_depth': 3, 'n_estimators': 100}   \n",
       "4                5                 10    {'max_depth': 5, 'n_estimators': 10}   \n",
       "5                5                 20    {'max_depth': 5, 'n_estimators': 20}   \n",
       "6                5                 50    {'max_depth': 5, 'n_estimators': 50}   \n",
       "7                5                100   {'max_depth': 5, 'n_estimators': 100}   \n",
       "8                7                 10    {'max_depth': 7, 'n_estimators': 10}   \n",
       "9                7                 20    {'max_depth': 7, 'n_estimators': 20}   \n",
       "10               7                 50    {'max_depth': 7, 'n_estimators': 50}   \n",
       "11               7                100   {'max_depth': 7, 'n_estimators': 100}   \n",
       "12              10                 10   {'max_depth': 10, 'n_estimators': 10}   \n",
       "13              10                 20   {'max_depth': 10, 'n_estimators': 20}   \n",
       "14              10                 50   {'max_depth': 10, 'n_estimators': 50}   \n",
       "15              10                100  {'max_depth': 10, 'n_estimators': 100}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0            0.865772           0.872483           0.863535   \n",
       "1            0.872483           0.865772           0.865772   \n",
       "2            0.865772           0.870246           0.868009   \n",
       "3            0.868009           0.872483           0.868009   \n",
       "4            0.874720           0.885906           0.899329   \n",
       "5            0.883669           0.899329           0.894855   \n",
       "6            0.888143           0.879195           0.892617   \n",
       "7            0.888143           0.906040           0.901566   \n",
       "8            0.897092           0.906040           0.894855   \n",
       "9            0.897092           0.899329           0.897092   \n",
       "10           0.892617           0.903803           0.899329   \n",
       "11           0.899329           0.906040           0.892617   \n",
       "12           0.894855           0.901566           0.885906   \n",
       "13           0.899329           0.881432           0.908277   \n",
       "14           0.903803           0.899329           0.903803   \n",
       "15           0.906040           0.910515           0.901566   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.854260           0.867713         0.864753        0.006019   \n",
       "1            0.856502           0.869955         0.866097        0.005439   \n",
       "2            0.854260           0.872197         0.866097        0.006298   \n",
       "3            0.854260           0.874439         0.867440        0.007054   \n",
       "4            0.869955           0.899103         0.885803        0.012115   \n",
       "5            0.869955           0.887892         0.887140        0.010159   \n",
       "6            0.874439           0.890135         0.884906        0.006920   \n",
       "7            0.883408           0.903587         0.896549        0.009035   \n",
       "8            0.872197           0.917040         0.897445        0.014847   \n",
       "9            0.887892           0.901345         0.896550        0.004610   \n",
       "10           0.887892           0.908072         0.898343        0.007313   \n",
       "11           0.885650           0.903587         0.897445        0.007451   \n",
       "12           0.890135           0.910314         0.896555        0.008625   \n",
       "13           0.883408           0.910314         0.896552        0.012132   \n",
       "14           0.881166           0.919283         0.901477        0.012207   \n",
       "15           0.885650           0.910314         0.902817        0.009188   \n",
       "\n",
       "    rank_test_score  \n",
       "0                16  \n",
       "1                14  \n",
       "2                14  \n",
       "3                13  \n",
       "4                11  \n",
       "5                10  \n",
       "6                12  \n",
       "7                 9  \n",
       "8                 5  \n",
       "9                 8  \n",
       "10                3  \n",
       "11                4  \n",
       "12                6  \n",
       "13                7  \n",
       "14                2  \n",
       "15                1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recherche_hyper.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Passer en production votre modèle d’apprentissage supervisé\n",
    "\n",
    "### Persistance de modèle avec Scikit-Learn\n",
    "\n",
    "Python possède plusieurs outils pour la persistance d’objets, c’est-à-dire pour stocker\n",
    "des objets dans des fichiers. Les objets de Scikit-Learn sont aussi dans cette\n",
    "situation. On utilise un format pickle qui aura l’extension .pkl.\n",
    "\n",
    "Par exemple, si nous voulons sauvegarder le dernier pipeline de traitement, nous\n",
    "allons utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s4d-asus-14\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./modele_grid.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(recherche_hyper, './modele_grid.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une fois ce modèle stocké, on peut très bien le réutiliser dans un autre cadre. Si\n",
    "nous créons un nouveau notebook, nous allons utiliser :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "#grid_search_mon_pipe = joblib.load('./data/modele_grid_pipe.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On peut ensuite appliquer le modèle avec tous les paramètres qui ont été appris :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```python\n",
    "grid_search_mon_pipe.predict(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L’utilisation d’un fichier Pickle dans un notebook est une technique assez simple et courante."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
